import torch
from transformers import BertTokenizer
from model import MultiHeadBERT
from config import Config

# æ˜ å°„å­—å…¸ï¼šæŠŠæ•°å­—è½¬å›äººç±»èƒ½æ‡‚çš„æ–‡å­—
ID2LABEL = {
    0: "ğŸ˜¡ å·®è¯„ (Negative)",
    1: "ğŸ˜ ä¸­ç«‹ (Neutral)",
    2: "ğŸ˜ å¥½è¯„ (Positive)",
    3: "âšª æœªæåŠ (None)"  
}

class SentimentPredictor:
    def __init__(self):
        print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        self.device = Config.DEVICE
        self.tokenizer = BertTokenizer.from_pretrained(Config.BERT_PATH)
        
        # 1. åˆå§‹åŒ–æ¨¡å‹ç»“æ„
        self.model = MultiHeadBERT(Config)
        
        # 2. åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
        model_path = f"{Config.MODEL_SAVE_DIR}/best_model.bin"
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        
        # 3. å¼€å¯è¯„ä¼°æ¨¡å¼ (éå¸¸é‡è¦ï¼å…³é—­ Dropout)
        self.model.to(self.device)
        self.model.eval()
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

    def predict(self, text):
        # æ•°æ®é¢„å¤„ç† (å’Œè®­ç»ƒæ—¶ä¸€æ¨¡ä¸€æ ·)
        inputs = self.tokenizer.encode_plus(
            text,
            None,
            add_special_tokens=True,
            max_length=Config.MAX_LEN,
            padding='max_length',
            truncation=True,
            return_token_type_ids=False
        )
        
        ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0).to(self.device)
        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            # outputs æ˜¯ä¸€ä¸ªåŒ…å« 8 ä¸ª Tensor çš„åˆ—è¡¨
            outputs = self.model(ids, mask)
        
        # è§£æç»“æœ
        results = {}
        for i, logits in enumerate(outputs):
            dim_name = Config.TARGET_COLS[i]
            
            # logits å½¢çŠ¶æ˜¯ [1, 3]ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ¦‚ç‡æœ€å¤§çš„é‚£ä¸ªç´¢å¼•
            probs = torch.softmax(logits, dim=1) # è½¬æ¢æˆæ¦‚ç‡
            pred_label_id = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_label_id].item() # ç½®ä¿¡åº¦
            
            # è¿‡æ»¤é€»è¾‘ï¼šå¦‚æœæ¨¡å‹å¯¹ç»“æœå¾ˆä¸è‡ªä¿¡ï¼ˆæ¯”å¦‚æœ€å¤§æ¦‚ç‡åªæœ‰0.4ï¼‰ï¼Œä¹Ÿå¯ä»¥è§†ä¸ºæœªæåŠ
            # è¿™é‡Œç®€å•å¤„ç†ï¼šç›´æ¥è¾“å‡ºé¢„æµ‹ç»“æœ
            results[dim_name] = {
                "label": ID2LABEL[pred_label_id],
                "score": f"{confidence:.2f}"
            }
            
        return results

if __name__ == "__main__":
    predictor = SentimentPredictor()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_sentences = [
        # 1. ã€ä»·æ ¼ä¸“é¡¹æµ‹è¯•ã€‘æ£€æŸ¥åˆšæ‰çš„è¡¥ä¸æœ‰æ²¡æœ‰ç”Ÿæ•ˆï¼ˆå…³é”®è¯ï¼šç™½å«–ã€ä¸¤å—é’±ã€åˆ’ç®—ï¼‰
        "è¿™ä¹Ÿå¤ªåˆ’ç®—äº†ï¼Œä¸€å¤©æ‰ä¸¤å—é’±ï¼Œå››èˆäº”å…¥ç®€ç›´å°±æ˜¯ç™½å«–ï¼ä»¥åå°±åœ¨ä½ å®¶ç§Ÿäº†ã€‚",

        # 2. ã€ç”»è´¨ä¸“é¡¹æµ‹è¯•ã€‘æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­¦ä¼šäº†â€œæ‰å¸§=å·®è¯„â€ï¼ˆå…³é”®è¯ï¼šPPTã€ä¼˜åŒ–å·®ï¼‰
        "æ¸¸æˆä¼˜åŒ–æå…¶åƒåœ¾ï¼ŒæŒæœºæ¨¡å¼ä¸‹ç®€ç›´å°±æ˜¯PPTï¼Œå¡é¡¿åˆ°æ— æ³•å‘¼å¸ï¼Œçœ¼ç›éƒ½è¦çäº†ã€‚",

        # 3. ã€æ··åˆæƒ…æ„ŸÂ·éš¾ç‚¹ã€‘æœåŠ¡æå¥½ + æ¸¸æˆæå·®ï¼ˆæµ‹è¯•æ¨¡å‹æ˜¯å¦ä¼šâ€œæƒ…æ„Ÿä¸²å‘³â€ï¼‰
        "è€æ¿äººè¶…çº§å¥½ï¼ŒåŠå¤œè¿˜å›æ¶ˆæ¯ï¼Œå‘è´§ä¹Ÿæ˜¯ç§’å‘ã€‚ä½†æ˜¯è¿™æ¸¸æˆçœŸçš„å¤ªæ— èŠäº†ï¼Œå‰§æƒ…çƒ‚å°¾ï¼Œç‹—éƒ½ä¸ç©ã€‚",

        # 4. ã€æ··åˆæƒ…æ„ŸÂ·éš¾ç‚¹ã€‘æ¸¸æˆæå¥½ + æˆè‰²æå·®ï¼ˆæµ‹è¯•æ¨¡å‹èƒ½å¦åŒºåˆ†â€œå†…å®¹â€å’Œâ€œè½½ä½“â€ï¼‰
        "å¼‚åº¦ä¹‹åˆƒ3çš„å‰§æƒ…å’ŒéŸ³ä¹çœŸçš„æ˜¯ç¥çº§ä½“éªŒï¼Œå“­å¾—ç¨€é‡Œå“—å•¦ã€‚å¯æƒœå‘æ¥çš„å¡å¸¦é‡‘æ‰‹æŒ‡éƒ½é»‘äº†ï¼Œæ“¦äº†åŠå¤©æ‰è¯»å‡ºæ¥ã€‚",

        # 5. ã€ä¸­ç«‹/ä¸€èˆ¬è¯„ä»·æµ‹è¯•ã€‘æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½è¯†åˆ«â€œNeutralâ€ï¼ˆå…³é”®è¯ï¼šä¸­è§„ä¸­çŸ©ã€è¿˜è¡Œï¼‰
        "å¿«é€’é€Ÿåº¦ä¸€èˆ¬å§ï¼Œä¸‰å¤©åˆ°çš„ï¼ŒåŒ…è£…ä¸­è§„ä¸­çŸ©ï¼Œæ¸¸æˆç©èµ·æ¥ä¹Ÿå°±é‚£æ ·ï¼Œæ²¡ç½‘ä¸Šå¹å¾—é‚£ä¹ˆç¥ã€‚",

        # 6. ã€å¤šç»´åº¦è½°ç‚¸ã€‘æµ‹è¯•æ¨¡å‹èƒ½å¦åŒæ—¶æ•æ‰ 4-5 ä¸ªç»´åº¦
        "ä»·æ ¼è™½ç„¶æœ‰ç‚¹å°è´µï¼Œä½†æ˜¯é¡ºä¸°ç‰¹å¿«çœŸçš„ç¨³ã€‚æ¸¸æˆç”»é¢æ˜¯é¡¶çº§çš„ï¼Œå°±æ˜¯é…éŸ³æœ‰ç‚¹å‡ºæˆï¼Œå¬ç€éš¾å—ã€‚"
    ]
    
    print("\n" + "="*50)
    for text in test_sentences:
        print(f"\nğŸ“ è¯„è®º: {text}")
        analysis = predictor.predict(text)
        
        print("ğŸ“Š åˆ†æç»“æœ:")
        for dim, res in analysis.items():
            print(f"   - {dim:<10}: {res['label']} (ç½®ä¿¡åº¦: {res['score']})")
    print("\n" + "="*50)